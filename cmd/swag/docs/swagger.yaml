basePath: /
definitions:
  claude.ConfigContent:
    properties:
      text:
        type: string
      type:
        description: '"text"'
        type: string
    type: object
  claude.Message:
    properties:
      content:
        type: string
      role:
        type: string
    type: object
  claude.MessageRequest:
    properties:
      max_tokens:
        type: integer
      messages:
        items:
          $ref: '#/definitions/claude.Message'
        type: array
      model:
        type: string
      stream:
        type: boolean
      system:
        type: string
    type: object
  claude.MessageResponse:
    properties:
      content:
        items:
          $ref: '#/definitions/claude.ConfigContent'
        type: array
      id:
        type: string
      model:
        type: string
      role:
        description: '"assistant"'
        type: string
      stop_reason:
        type: string
      type:
        description: '"message"'
        type: string
      usage:
        $ref: '#/definitions/claude.Usage'
    type: object
  claude.ModelData:
    properties:
      created_at:
        type: integer
      display_name:
        type: string
      id:
        type: string
      type:
        type: string
    type: object
  claude.ModelListResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/claude.ModelData'
        type: array
    type: object
  claude.Usage:
    properties:
      input_tokens:
        type: integer
      output_tokens:
        type: integer
    type: object
  gemini.Candidate:
    properties:
      content:
        $ref: '#/definitions/gemini.Content'
      finishReason:
        type: string
      index:
        type: integer
    type: object
  gemini.Content:
    properties:
      parts:
        items:
          $ref: '#/definitions/gemini.Part'
        type: array
      role:
        type: string
    type: object
  gemini.GeminiGenerateRequest:
    properties:
      contents:
        items:
          $ref: '#/definitions/gemini.Content'
        type: array
      generationConfig:
        $ref: '#/definitions/gemini.GenerationConfig'
    type: object
  gemini.GeminiGenerateResponse:
    properties:
      candidates:
        items:
          $ref: '#/definitions/gemini.Candidate'
        type: array
      usageMetadata:
        $ref: '#/definitions/gemini.UsageMetadata'
    type: object
  gemini.GeminiModel:
    properties:
      description:
        type: string
      displayName:
        type: string
      inputTokenLimit:
        type: integer
      name:
        type: string
      outputTokenLimit:
        type: integer
      supportedGenerationMethods:
        items:
          type: string
        type: array
      version:
        type: string
    type: object
  gemini.GeminiModelsResponse:
    properties:
      models:
        items:
          $ref: '#/definitions/gemini.GeminiModel'
        type: array
    type: object
  gemini.GenerationConfig:
    properties:
      maxOutputTokens:
        type: integer
      stopSequences:
        items:
          type: string
        type: array
      temperature:
        type: number
      topK:
        type: integer
      topP:
        type: number
    type: object
  gemini.InlineData:
    properties:
      data:
        description: Base64
        type: string
      mimeType:
        type: string
    type: object
  gemini.Part:
    properties:
      inlineData:
        $ref: '#/definitions/gemini.InlineData'
      text:
        type: string
    type: object
  gemini.UsageMetadata:
    properties:
      candidatesTokenCount:
        type: integer
      promptTokenCount:
        type: integer
      totalTokenCount:
        type: integer
    type: object
  openai.ChatCompletionRequest:
    properties:
      max_tokens:
        type: integer
      messages:
        items:
          $ref: '#/definitions/openai.Message'
        type: array
      model:
        type: string
      stream:
        type: boolean
      temperature:
        type: number
    type: object
  openai.ChatCompletionResponse:
    properties:
      choices:
        items:
          $ref: '#/definitions/openai.Choice'
        type: array
      created:
        type: integer
      id:
        type: string
      model:
        type: string
      object:
        type: string
      usage:
        $ref: '#/definitions/openai.Usage'
    type: object
  openai.Choice:
    properties:
      finish_reason:
        type: string
      index:
        type: integer
      message:
        $ref: '#/definitions/openai.Message'
    type: object
  openai.Error:
    properties:
      code:
        type: string
      message:
        type: string
      type:
        type: string
    type: object
  openai.ErrorResponse:
    properties:
      error:
        $ref: '#/definitions/openai.Error'
    type: object
  openai.Message:
    properties:
      content:
        type: string
      role:
        type: string
    type: object
  openai.ModelData:
    properties:
      created:
        type: integer
      id:
        type: string
      object:
        type: string
      owned_by:
        type: string
    type: object
  openai.ModelListResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/openai.ModelData'
        type: array
      object:
        type: string
    type: object
  openai.Usage:
    properties:
      completion_tokens:
        type: integer
      prompt_tokens:
        type: integer
      total_tokens:
        type: integer
    type: object
host: localhost:3000
info:
  contact: {}
  description: "\U0001F680 High-performance WebAI-to-API gateway. Seamlessly bridge
    Google Gemini into standardized OpenAI, Anthropic (Claude), and Google Native
    REST APIs."
  title: AI Bridges API
  version: "1.0"
paths:
  /v1/chat/completions:
    post:
      consumes:
      - application/json
      description: Accepts requests in OpenAI format
      parameters:
      - description: Chat request
        in: body
        name: request
        required: true
        schema:
          $ref: '#/definitions/openai.ChatCompletionRequest'
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/openai.ChatCompletionResponse'
        "400":
          description: Bad Request
          schema:
            $ref: '#/definitions/openai.ErrorResponse'
        "500":
          description: Internal Server Error
          schema:
            $ref: '#/definitions/openai.ErrorResponse'
      summary: OpenAI-compatible chat completions
      tags:
      - OpenAI Compatible
  /v1/messages:
    post:
      consumes:
      - application/json
      description: Accepts requests in Anthropic Claude format
      parameters:
      - description: Message request
        in: body
        name: request
        required: true
        schema:
          $ref: '#/definitions/claude.MessageRequest'
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/claude.MessageResponse'
        "400":
          description: Bad Request
          schema:
            additionalProperties: true
            type: object
        "500":
          description: Internal Server Error
          schema:
            additionalProperties: true
            type: object
      summary: Claude-compatible chat
      tags:
      - Claude Compatible
  /v1/messages/count_tokens:
    post:
      consumes:
      - application/json
      description: Estimates token count for a Claude request
      parameters:
      - description: Message request
        in: body
        name: request
        required: true
        schema:
          $ref: '#/definitions/claude.MessageRequest'
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            additionalProperties: true
            type: object
      summary: Count tokens
      tags:
      - Claude Compatible
  /v1/models:
    get:
      consumes:
      - application/json
      description: Returns a list of models supported by the OpenAI-compatible API
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/openai.ModelListResponse'
      summary: List OpenAI models
      tags:
      - OpenAI Compatible
  /v1/models/{model_id}:
    get:
      consumes:
      - application/json
      description: Returns a specific Claude model by ID
      parameters:
      - description: Model ID
        in: path
        name: model_id
        required: true
        type: string
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/claude.ModelData'
      summary: Get Claude model by ID
      tags:
      - Claude Compatible
  /v1beta/models:
    get:
      description: Returns models supported by the Gemini provider
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/gemini.GeminiModelsResponse'
      summary: List Gemini Models (v1beta)
      tags:
      - Gemini v1beta
  /v1beta/models/{model}:generateContent:
    post:
      consumes:
      - application/json
      description: Compatible with official Google Gemini API
      parameters:
      - description: Model name
        in: path
        name: model
        required: true
        type: string
      - description: Gemini request
        in: body
        name: request
        required: true
        schema:
          $ref: '#/definitions/gemini.GeminiGenerateRequest'
      produces:
      - application/json
      responses:
        "200":
          description: OK
          schema:
            $ref: '#/definitions/gemini.GeminiGenerateResponse'
      summary: Generate Content (v1beta)
      tags:
      - Gemini v1beta
  /v1beta/models/{model}:streamGenerateContent:
    post:
      consumes:
      - application/json
      description: Returns a stream of JSON chunks (standard Gemini format)
      parameters:
      - description: Model name
        in: path
        name: model
        required: true
        type: string
      - description: Gemini request
        in: body
        name: request
        required: true
        schema:
          $ref: '#/definitions/gemini.GeminiGenerateRequest'
      produces:
      - application/json
      responses: {}
      summary: Stream Generate Content (v1beta)
      tags:
      - Gemini v1beta
swagger: "2.0"
